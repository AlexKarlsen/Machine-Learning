Taking advantage of the pairwise structure of the FIN-Benthic data set significantly improves the machine learning algorithm's classification performance. The double amount of information seems very useful and can be backed up by looking at the raw images. In most cases the images resembles each other, however there are cases, where the images seems to be taken from an unfortunate angle. The doubled information seems to handle this problem. Nonetheless inspecting the predicted class labels, one can see, that they are still not completely pairwise segmented. A postprocessing step if using a probabilistic classification model can be proposed. Summing the outcome of class probabilities for the pair and classify to the most probable for the pair could be advantageous.

A future step is to look at random search instead grid search. Although improvements where found using grid search and I started with coarse grids and narrowed down the search space using finer grid, there might be combinations, that I did not consider and which could have given better results. 

I have tested out a set of different classification method and the best performing seems to be Support Vector Machines and Fully-Connected Neural Network for the vectorized AlexNet features. It would have been interesting to train a state-of-the-art CNN over a long period of time, to see if the features from such a network would in fact improve the features, thus gives a better accuracy for all the methods. Nowadays architectures like GoogleNetV4 accuracy of 0.803 on the ImageNet data set\cite{SzegedyIV16}, which have the size required to train such deep models. Transfer learning reuses the weights from e.g. ImageNet to solve a another classification task. The model can be fine-tuned to better fit the special cases of the new data set. 